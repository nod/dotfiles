#!/usr/bin/env python

import re
from os import path
from subprocess import Popen
from urllib import urlopen
from zlib import adler32

try:
	from BeautifulSoup import BeautifulStoneSoup
except ImportError:
	print "you need to install BeautifulSoup. Exiting"
	raise SystemExit

fpath = path.expanduser("~/.redditurls")

DEFAULT_LIMIT = 25

def go(subreddit, limit, new):

    if not path.exists(fpath):
        with open(fpath, "w") as newf:
            newf.write('')

    cat = '' if not new else 'new/' # use hash table for others
    srch = re.compile('.+(https?://[a-zA-Z0-9./?=_-]+).+?\[link\]')
    soup = BeautifulStoneSoup(urlopen(
        'http://www.reddit.com/r/{}/{}.rss'.format(subreddit, cat)
        ))

    new_count = 0
    for i in soup.findAll('item', limit=limit):
        descr = i.description.text
        url = srch.search(descr).groups()[0]
        csum = adler32(url)

        f = open(fpath)
        if str(csum)+'\n' not in f:
            f.close()
            f = open(fpath, 'a')
            print >>f, csum
            cmd = 'open -g {}'.format(url)
            p = Popen((cmd.split()))
            p.wait()
            new_count += 1
        f.close()
    if new_count:
        print "opened {} new links".format(new_count)


def usage():
    print """reddit [-n -c <count>] <SUBREDDIT> [SUBREDDIT...]"""


if __name__ == '__main__':

    import sys
    import getopt

    limit, new = DEFAULT_LIMIT, False

    try:
        opt, subreddits = getopt.getopt(sys.argv[1:], 'nc:')
        assert(subreddits)
        for o,a in opt:
            if o == '-c': limit = int(a)
            if o == '-n': new = True
    except:
        usage()
        raise SystemExit

    for subr in subreddits:
        go(subr, limit, new) # use kwargs

